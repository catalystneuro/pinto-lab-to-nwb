{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6242b563-faf9-411b-b61e-ff6d5d802609",
   "metadata": {},
   "source": [
    "# Widefield tutorial\n",
    "\n",
    "This tutorial demonstraces how to access the *Widefield dataset* using `pynwb`. \n",
    "\n",
    "This dataset contains the Widefield imaging data, behavior measurements from the ViRMEN system and pose estimation data from LightningPose.\n",
    "\n",
    "Contents:\n",
    "\n",
    "- [Reading an NWB file](#read-nwb)\n",
    "- [Access subject and task metadata](#access-subject)\n",
    "- [Access Imaging](#access-imaging)\n",
    "- [Access Behavior](#access-behavior)\n",
    "- [View NWB files](#view-nwb)\n",
    "\n",
    "A schematic representation where the source data is saved in NWB: \n",
    "\n",
    "![Alt text](data_types_eyetracking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc8942c-2b51-4bd9-9e87-51cdd58f25ef",
   "metadata": {},
   "source": [
    "# Reading an NWB file <a name=\"read-nwb\"></a>\n",
    "\n",
    "This section demonstrates how to read an NWB file using `pynwb`.\n",
    "\n",
    "Based on the [NWB File Basics](https://pynwb.readthedocs.io/en/stable/tutorials/general/plot_file.html#sphx-glr-tutorials-general-plot-file-py) tutorial from [PyNWB](https://pynwb.readthedocs.io/en/stable/#).\n",
    "\n",
    "An [NWBFile](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.NWBFile) represents a single session of an experiment. Each NWBFile must have a `session description`, `identifier`, and `session start time`.\n",
    "\n",
    "Reading is carried out using the [NWBHDF5IO](https://pynwb.readthedocs.io/en/stable/pynwb.html#pynwb.NWBHDF5IO) class. To read the NWB file use the read mode (\"r\") to retrieve an NWBFile object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2968627-3cdd-4c65-825c-4e239cf9a5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO\n",
    "\n",
    "# The file path to a .nwb file\n",
    "nwbfile_path = \"/Users/weian/data/210944/sub-Cherry/sub-Cherry_ses-20230802-20hz-1_behavior+image+ophys.nwb\"\n",
    "io = NWBHDF5IO(path=nwbfile_path, mode=\"r\", load_namespaces=True)\n",
    "nwbfile = io.read()\n",
    "\n",
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100571c5-1d17-4d2f-b6e8-2629457964a7",
   "metadata": {},
   "source": [
    "Importantly, the `session start time` is the reference time for all timestamps in the file. For instance, an event with a timestamp of 0 in the file means the event occurred exactly at the session start time.\n",
    "\n",
    "The `session_start_time` is extracted from the `date` and `time` variables from the ViRMEN file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0185044a-0bd2-431c-9290-435e02689ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.session_start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d247090-5cfb-47b1-a1a4-8a7c87921a38",
   "metadata": {},
   "source": [
    "# Access subject and task related metadata <a name=\"access-subject\"></a>\n",
    "\n",
    "## Access subject metadata\n",
    "\n",
    "This section demonstrates how to access the [Subject](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.Subject) field in an NWB file.\n",
    "\n",
    "The [Subject](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.Subject) field can be accessed as `nwbfile.subject`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483b9a74-c5f0-4f59-b422-1a3a7a9c5002",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47277bac-d8a0-4ce0-a20b-79721eac0e7a",
   "metadata": {},
   "source": [
    "## Access ViRMEN experimental metadata (mazes table, stimulus protocol parameters)\n",
    "\n",
    "This section demonstrates how to access the task related metadata in an NWB file.\n",
    "\n",
    "The ViRMEN experimental metadata is stored in a [LabMetaData](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.LabMetaData) extension ([ndx-pinto-metadata](https://github.com/catalystneuro/ndx-pinto-metadata)). \n",
    "\n",
    "The [LabMetaData](https://pynwb.readthedocs.io/en/stable/pynwb.file.html#pynwb.file.LabMetaData) object can be accessed as `nwbfile.lab_meta_data[\"LabMetaData\"]`.\n",
    "\n",
    "The parameters for the mazes is added to the `mazes` table within `nwbfile.lab_meta_data[\"LabMetaData\"]` which can be accessed as `nwbfile.lab_meta_data[\"LabMetaData\"].mazes`. \n",
    "\n",
    "Data arrays are read passively from the file. Accessing the data attribute of the `mazes` object does not read the data values, but presents an HDF5 object that can be indexed to read data. You can use the [:] operator to read the entire data array into memory as `nwbfile.lab_meta_data[\"LabMetaData\"].mazes[:]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caff60-9c9e-4963-936a-0222ad597d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nwbfile.lab_meta_data[\"LabMetaData\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d880cd-ef57-454e-85d4-5cc3df1ce3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.lab_meta_data[\"LabMetaData\"].mazes[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adbdb8b-13da-43a2-b26a-b579edc57ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.lab_meta_data[\"LabMetaData\"].stimulus_protocol[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709c01f6-b254-4cdb-9a9e-e18ff67fe771",
   "metadata": {},
   "source": [
    "## Access trials\n",
    "\n",
    "Behavior trials are stored in `nwbfile.trials`. The `start_time` denotes the start time of each trial in seconds relative to the global session start time (using the \"StartOfTrial\" column from ViRMEN `.mat` file).\n",
    "The `stop_time` denotes the end time of each trial in seconds relative to the global session start time\n",
    "(using the \"EndOfTrial\" column from the ViRMEN `.mat` file).\n",
    "\n",
    "`nwbfile.trials` can be converted to a pandas DataFrame for convenient analysis using `nwbfile.trials.to_dataframe`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bd3de0-7d11-432c-a9cc-32e21ce63a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = nwbfile.trials.to_dataframe()\n",
    "\n",
    "trials[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129757c1-a387-4c28-be56-7d5317525a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials[trials[\"trial_type\"] == \"right\"][:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc72048-3dc7-4b35-a411-e5507176ef35",
   "metadata": {},
   "source": [
    "# Access Widefield Imaging <a name=\"access-imaging\"></a>\n",
    "\n",
    "This section demonstraces how to access the raw and processed Widefield imaging data.\n",
    "\n",
    "`NWB` organizes data into different groups depending on the type of data. Groups can be thought of as folders within the file. Here are some of the groups within an NWBFile and the types of data they are intended to store:\n",
    "\n",
    "- `acquisition`: raw, acquired data that should never change\n",
    "- `processing`: processed data, typically the results of preprocessing algorithms and could change\n",
    "\n",
    "## Raw Widefield Imaging\n",
    "\n",
    "The raw Widefield imaging data is stored in `pynwb.ophys.OnePhotonSeries` objects (blue and violet separately) which is added to `nwbfile.acquisition`. The blue frames can be accessed as `nwbfile.acquisition['OnePhotonSeriesBlue']`, the violet frames as `nwbfile.acquisition['OnePhotonSeriesViolet']`.\n",
    "\n",
    "The data in [OnePhotonSeries](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.OnePhotonSeries) is stored as a three dimensional array: the first dimension is time (frame), the second and third dimensions represent x and y (width by height). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9621b78-2c39-49fa-8106-d3e277252468",
   "metadata": {},
   "outputs": [],
   "source": [
    "photon_series_blue = nwbfile.acquisition['OnePhotonSeriesBlue']\n",
    "photon_series_violet = nwbfile.acquisition['OnePhotonSeriesViolet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef00fe3-cb56-4efe-89bb-946bb9bc42b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the imaging data.\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(photon_series_blue.data[50].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Blue\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(photon_series_violet.data[50].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Violet\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7bcda-7c49-4d8c-8e16-84775a4e4b88",
   "metadata": {},
   "source": [
    "The timestamps for the blue frames can be accessed as `nwbfile.acquisition['OnePhotonSeriesBlue'].timestamps`.\n",
    "\n",
    "The blue frame timestamps that are aligned with the behavior clock are added from the `wf_behav_sync.mat` file.\n",
    "The violet frame timestamps are aligned to the blue frame timestamps by interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19879672-07e2-443c-ac36-3952200eb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "photon_series_blue.timestamps[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65632247-717f-43da-bd24-3a6b738b4e73",
   "metadata": {},
   "source": [
    "The processed imaging data is stored in the \"ophys\" processing module, which can be accessed as `nwbfile.processing[\"ophys\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c5601-ddca-4336-829c-f2b42bd07828",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"ophys\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982ff4d7-4953-4bea-a20b-c4db5d00d984",
   "metadata": {},
   "source": [
    "## Motion Correction\n",
    "\n",
    "The x,y shifts for the blue and violet frames is added as [TimeSeries](https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries) objects.\n",
    "\n",
    "The motion correction series for the blue frames can be accessed as `nwbfile.processing[\"ophys\"][\"MotionCorrectionSeriesBlue\"]`.\n",
    "\n",
    "The timestamps for the motion correction series references the same timestamps as for the raw imaging data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4ae122-b92e-465d-9e09-cc813f79388b",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_correction_blue = nwbfile.processing[\"ophys\"][\"MotionCorrectionSeriesBlue\"]\n",
    "motion_correction_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f9bd0-daf8-43d3-a14c-2dd25a658bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_correction_blue.data[:10], motion_correction_blue.timestamps[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4558f6d-e9ac-4bba-8e70-0f80ea4b0c29",
   "metadata": {},
   "source": [
    "## Processed Widefield Imaging\n",
    "\n",
    "The downsampled imaging data for the blue frames can accessed as `nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedBlue\"]`.\n",
    "\n",
    "The data in [OnePhotonSeries](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.OnePhotonSeries) is stored as a three dimensional array: the first dimension is time (frame), the second and third dimensions represent x and y (width by height). \n",
    "\n",
    "The binned image size is (128, 128) which can be accessed with the \"dimension\" attribute in `nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedBlue\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f7592b-1235-4d97-8f63-a09747f9d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedBlue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06080884-70d2-4bbe-b4cf-5ab4607e9578",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedBlue\"].dimension[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d0ef1-a474-48fc-9106-3a80a188834a",
   "metadata": {},
   "source": [
    "## Accessing the segmentation data\n",
    "\n",
    "The segmentation output for the Widefield Imaging data is stored in `nwbfile.processing[\"ophys\"]`. \n",
    "\n",
    "In NWB, the [PlaneSegmentation](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.PlaneSegmentation) class stores the detected regions of interest in the [OnePhotonSeries](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.OnePhotonSeries) data. The [ImageSegmentation](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.ImageSegmentation) can contain multiple `PlaneSegmentation` tables, so that we can store results of different segmentation algorithms or different segmentation classes.\n",
    "\n",
    "We can access the plane segmentation for the processed [OnePhotonSeries](https://pynwb.readthedocs.io/en/stable/pynwb.ophys.html#pynwb.ophys.OnePhotonSeries) data (blue frames) as \n",
    "`nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\"PlaneSegmentationProcessedBlue\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0618a5c-85c1-4a22-b80e-c8dff5942800",
   "metadata": {},
   "outputs": [],
   "source": [
    "plane_segmentation = nwbfile.processing[\"ophys\"][\"ImageSegmentation\"][\"PlaneSegmentationProcessedBlue\"][:]\n",
    "plane_segmentation[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4faa4c-9d0f-473d-b441-4f5e1fef2bb2",
   "metadata": {},
   "source": [
    "The summary images of the segmentation are stored in [Images](https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.Images) container in NWB. \n",
    "\n",
    "The manual mask and contrast based vasculature mask for the blue channel (full size image) can be accessed \n",
    "as `nwbfile.processing[\"ophys\"][\"SegmentationImagesBlue\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4974b7a-c2e5-4e75-b19c-1bc3d13ad27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_blue = nwbfile.processing[\"ophys\"][\"SegmentationImagesBlue\"]\n",
    "images_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e3f92-8c66-4108-b1d6-930bfb3a6ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(photon_series_blue.data[50].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Blue\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(images_blue.images[\"manual\"].data[:].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Manual mask\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(images_blue.images[\"vasculature\"].data[:].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Vasculature mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85b126d-4cf9-44ad-9f81-5f2b4c5dec84",
   "metadata": {},
   "source": [
    "The PCA mask and the vasculature mask for the blue channel on the binned session image can be accessed from \n",
    "`nwbfile.processing[\"ophys\"][\"SegmentationImages\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e33b68-ac51-4159-8d1e-a77868f1ca27",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"ophys\"][\"SegmentationImages\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c9fb0b-d1b2-454a-9513-cd2d455acce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_blue = nwbfile.processing[\"ophys\"][\"SegmentationImages\"]\n",
    "\n",
    "plt.imshow(nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedBlue\"].data[50].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Blue\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(images_blue.images[\"pca_blue\"].data[:].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"PCA mask\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(images_blue.images[\"vasculature\"].data[:].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Vasculature mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8067a7-7cc8-4d39-89e2-1845e0528b2d",
   "metadata": {},
   "source": [
    "The PCA mask for the violet channel on the binned session image can be accessed from \n",
    "`nwbfile.processing[\"ophys\"][\"SegmentationImagesProcessedViolet\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71eb574d-ad37-4754-b7ff-83fba91b7622",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_violet = nwbfile.processing[\"ophys\"][\"SegmentationImagesProcessedViolet\"]\n",
    "images_violet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75150a-f546-49e5-802f-dc05d74902cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nwbfile.processing[\"ophys\"][\"OnePhotonSeriesProcessedViolet\"].data[50].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"Violet\")\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(images_violet.images[\"pca_violet\"].data[:].T, aspect=\"auto\", cmap=\"Greys\")\n",
    "plt.title(\"PCA mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d3c4f-db70-4168-9631-dc844719954a",
   "metadata": {},
   "source": [
    "# Access Behavior <a name=\"access-behavior\"></a>\n",
    "\n",
    "This section demonstrates how to access behavioral data from the [pynwb.behavior](https://pynwb.readthedocs.io/en/stable/pynwb.behavior.html#module-pynwb.behavior) module.\n",
    "\n",
    "The behavior data is stored in the \"behavior\" processing module, which can be accessed as `nwbfile.processing[\"behavior\"]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dc9045-0ae2-4515-ab56-f8344623c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2545d3-55d2-4a3e-a8e0-fe046331bc72",
   "metadata": {},
   "source": [
    "## Access Position\n",
    "\n",
    "[SpatialSeries](https://pynwb.readthedocs.io/en/stable/pynwb.behavior.html#pynwb.behavior.SpatialSeries) is a subclass of [TimeSeries](https://pynwb.readthedocs.io/en/stable/pynwb.base.html#pynwb.base.TimeSeries) that represents data in space, such as the spatial direction, e.g., of gaze or travel, or position of an animal over time.\n",
    "\n",
    "The x, y (z) position of the animal is stored stored in `SpatialSeries` object inside the [Position](https://pynwb.readthedocs.io/en/stable/pynwb.behavior.html#pynwb.behavior.Position) container.\n",
    "\n",
    "The Position container can be accessed as `nwbfile.processing[\"behavior\"][\"Position\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8542f-fa13-49d6-9478-85601f3d8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"Position\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e02705-d97c-4d4d-bdf8-ed4b5feb40c3",
   "metadata": {},
   "source": [
    "The x, y, z position of the animal by ViRMEN iteration can be accessed as `nwbfile.processing[\"behavior\"][\"Position\"][\"SpatialSeries\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9202caa-01e4-4307-a281-61f23c187774",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_by_virmen = nwbfile.processing[\"behavior\"][\"Position\"][\"SpatialSeries\"]\n",
    "position_by_virmen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79bfb0-b8c6-40ac-8932-e44b98071440",
   "metadata": {},
   "source": [
    "The x, y, position of the animal averaged over the iterations for each frame can be accessed as `nwbfile.processing[\"behavior\"][\"Position\"][\"SpatialSeriesByImFrame\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea6032-e450-4a41-a2cf-4383afa0c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_by_frame = nwbfile.processing[\"behavior\"][\"Position\"][\"SpatialSeriesByImFrame\"]\n",
    "position_by_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edfe90-2521-490d-82a5-0bffec26d241",
   "metadata": {},
   "source": [
    "The \"SpatialSeriesByImFrame\" has the same time basis as the imaging data (blue frames):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a95a1a4-032a-4c2c-8491-eb6da66a2640",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "position_by_frame.timestamps.shape, photon_series_blue.timestamps.shape,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432ea336-fad7-412e-a23d-377f296ea009",
   "metadata": {},
   "source": [
    "# Access Eye Tracking <a name=\"access-eyetracking\"></a>\n",
    "\n",
    "This section demonstrates how to access the pose estimation data acquired from Lightning Pose.\n",
    "\n",
    "The original video is added as [ImageSeries](https://pynwb.readthedocs.io/en/stable/pynwb.image.html#pynwb.image.ImageSeries) with *external* mode. In external mode the video data is not stored in NWB, instead we use [external links](https://www.dandiarchive.org/2022/03/03/external-links-organize.html) to video files using a relative path to that file on disk. In this case the `data` attribute of [ImageSeries](https://pynwb.readthedocs.io/en/stable/pynwb.image.html#pynwb.image.ImageSeries) is empty, instead we have `external_file` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16821612-25b6-45f9-8d62-6067f5ff3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.acquisition['ImageSeriesOriginalVideo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a1ea21-15d8-4db3-b17e-076d0d126e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.acquisition['ImageSeriesOriginalVideo'].external_file[:][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4505f474-9ba2-4e93-a5c8-7858e778e705",
   "metadata": {},
   "source": [
    "Similarly to the original video, the labeled video (if available) is also added as [ImageSeries](https://pynwb.readthedocs.io/en/stable/pynwb.image.html#pynwb.image.ImageSeries) with *external* mode.\n",
    "\n",
    "The labeled video is added to the \"behavior\" processing module and can be accessed as `nwbfile.processing[\"behavior\"][\"ImageSeriesLabeledVideo\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45555e1-c4dc-4cc0-969a-65d520cadab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"ImageSeriesLabeledVideo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601dcd9a-9fae-424e-8da3-c8bc2b471193",
   "metadata": {},
   "source": [
    "To store the pose estimation data in NWB, we are using an NWB extension [ndx-pose](https://github.com/rly/ndx-pose). The `PoseEstimation` container stores the estimated position data (`PoseEstimationSeries`) for multiple body parts computed from the original video.\n",
    "\n",
    "We can access `PoseEstimation` as `nwbfile.processing[\"behavior\"][\"PoseEstimation\"]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b44bbde-a2ed-4bd2-adef-7a08ddb95e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"PoseEstimation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eab814-71eb-4b0f-8af3-32fca53c23a3",
   "metadata": {},
   "source": [
    "The `PoseEstimationSeries` stores the estimated positions (x, y) of a body part over time as well as the confidence of the estimated positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93cdfad-ee04-4ab6-9517-4a2f1a5b55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"PoseEstimation\"].pose_estimation_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e606d-8242-49d4-bf38-3a95cdfa0fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"PoseEstimation\"][\"PoseEstimationSeriesDRpupil\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b1d7bb-a86d-4392-8e60-8cb9f99e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"PoseEstimation\"][\"PoseEstimationSeriesDRpupil\"].data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb3add2-fe3f-4929-bc49-6919e0f2e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.processing[\"behavior\"][\"PoseEstimation\"][\"PoseEstimationSeriesDRpupil\"].confidence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffd849-5e5a-4837-a032-8ea966d9c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nwbwidgets import nwb2widget\n",
    "\n",
    "nwb2widget(nwbfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53208589-a659-433c-a699-1c693b0446e3",
   "metadata": {},
   "source": [
    "We also use [Neurosift](https://github.com/flatironinstitute/neurosift), a platform for the visualization of neuroscience data in the web browser."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
